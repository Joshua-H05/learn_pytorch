{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Working with images\n",
    "- Need to load images from common image formats & turn them into tensors\n",
    "- Images are represented as a collection of scalars in a regular grid\n",
    "    - Could have a single scalar per grid point -> grayscale\n",
    "    - Could have RGB color channels or multiple scalars that represent features, e.g. depth\n",
    "    - Usually represented as 8-bit ints, but could also use 12 or 16 bit ints  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a07fb31a63ab645f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading images \n",
    "-  `imageio` library: Handles different data types with a uniform API\n",
    "- `torchvision` is generally a good alternative"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79704b93b49f14f2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import imageio.v2\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.202212800Z",
     "start_time": "2023-12-10T16:00:40.092267500Z"
    }
   },
   "id": "dcd2f443a7628407"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "img_arr = imageio.v2.imread('bobby.jpg') # Returns an n-d array: height, width, channels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.308648300Z",
     "start_time": "2023-12-10T16:00:41.203212600Z"
    }
   },
   "id": "18a511bf1cbcb970"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((720, 1280, 3), numpy.ndarray)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr.shape, type(img_arr) # Numpy array-like object: 2 spacial dimensions & a third dim for rgb values\n",
    "# Issue: torch requires tensors to be laid out as follows: Channels X height X width"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.318164700Z",
     "start_time": "2023-12-10T16:00:41.308648300Z"
    }
   },
   "id": "dae74ad1ff6a4dfb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Use torch.permute to solve\n",
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1) # move the color channels up to the first dim-> Operation does not copy the tensor (uses same underlying storage)-> Cheap operation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.319162300Z",
     "start_time": "2023-12-10T16:00:41.313649400Z"
    }
   },
   "id": "831ed3e62c7042f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a dataset with multiple images\n",
    "- Stack tensors along the first dim\n",
    "- More efficient alternative: Use `stack` to build up the tensor: Preallocate a tensor of the correct size then fill it with images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "861b05ae53503557"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = 'image-cats'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.320162500Z",
     "start_time": "2023-12-10T16:00:41.318164700Z"
    }
   },
   "id": "2948acd3956b7859"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.325690800Z",
     "start_time": "2023-12-10T16:00:41.324691Z"
    }
   },
   "id": "11c6b2085193ce57"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']\n",
    "# list comp: lists all the files in the specified dir & adds to a list if the file is a png\n",
    "#  os.path.splitext(name)[-1] : extracts the file extension of the file name-> splits file name into tuple (root, extension)-> [-1] extracts the extension & makes sure it is a png"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.330627400Z",
     "start_time": "2023-12-10T16:00:41.326691900Z"
    }
   },
   "id": "a775553d748dc424"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.v2.imread(os.path.join(data_dir, filename)) # use imageio to read in the images (use os to join the filename with the rest of the path)\n",
    "    img = torch.from_numpy(img_arr)\n",
    "    out = img.permute(2, 0, 1)[:3] # only want first 3 (discard any other numbers e.g. transparency)\n",
    "    batch[i] = out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.381232400Z",
     "start_time": "2023-12-10T16:00:41.329619600Z"
    }
   },
   "id": "28b0465f21cd10e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data normalization\n",
    "- Neural networks exhibit the best performance when the input data ranges from 0 to 1 or from -1 to 1\n",
    "- Need to cast tensors to floating-points & normalize the pixel values\n",
    "- Have a few options\n",
    "    - divide pixel values by 255-> returns values bound between 0 & 1\n",
    "    - Compute the mean & standard deviation of the input & scale so that the output has 0 mean & unit standard deviation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "760d59920d065c33"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Option 1\n",
    "batch = batch.float()\n",
    "# batch /= 255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.382739Z",
     "start_time": "2023-12-10T16:00:41.373232200Z"
    }
   },
   "id": "6eed06457ba330ae"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Option 2\n",
    "n_channels = batch.shape[1] # Grab the number of channels (shape: batch size X num_channels X height X Width)\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) /std"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.390261200Z",
     "start_time": "2023-12-10T16:00:41.378233Z"
    }
   },
   "id": "e104a12f6d9530b2"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.391299600Z",
     "start_time": "2023-12-10T16:00:41.387260500Z"
    }
   },
   "id": "ddac901545c8d4e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.1439,  0.0730, -0.4234,  ...,  0.0375,  0.0198,  0.1794],\n          [ 0.4631, -0.2461,  0.3035,  ..., -0.4944, -0.2107, -0.1752],\n          [-0.3703,  0.1439, -0.7249,  ..., -0.2993, -0.0866,  0.2858],\n          ...,\n          [-0.5653, -0.3171, -0.3348,  ..., -0.3703, -0.5298, -0.6362],\n          [-0.3348, -0.3171, -0.4412,  ..., -0.5830, -0.4766, -0.6007],\n          [-0.3348, -0.4412, -0.5298,  ..., -0.6185, -0.4766, -0.4944]],\n\n         [[ 0.4632,  0.3874, -0.1058,  ...,  0.3874,  0.3874,  0.6150],\n          [ 0.8615,  0.0839,  0.6529,  ..., -0.1816,  0.1408,  0.1787],\n          [-0.0299,  0.4822, -0.4661,  ...,  0.0649,  0.2736,  0.7098],\n          ...,\n          [-0.2954, -0.0868, -0.0678,  ...,  0.0460, -0.1247, -0.2196],\n          [-0.0678, -0.0678, -0.1627,  ..., -0.1627, -0.0489, -0.1816],\n          [-0.0678, -0.2006, -0.2385,  ..., -0.2196, -0.0868, -0.0678]],\n\n         [[ 0.7792,  0.6573,  0.1495,  ...,  0.8198,  0.8401,  1.1041],\n          [ 1.3072,  0.3933,  0.9417,  ...,  0.2308,  0.5761,  0.6167],\n          [ 0.2714,  0.8401, -0.2161,  ...,  0.4339,  0.6979,  1.1245],\n          ...,\n          [ 0.0480,  0.3526,  0.2917,  ...,  0.6979,  0.4948,  0.3526],\n          [ 0.3526,  0.3526,  0.1495,  ...,  0.3933,  0.5354,  0.3933],\n          [ 0.3323,  0.1495,  0.0886,  ...,  0.3526,  0.4948,  0.5151]]],\n\n\n        [[[ 0.9595,  0.7999,  0.7467,  ..., -2.3915, -2.3915, -2.4092],\n          [ 0.9063,  0.7822,  0.7290,  ..., -2.3738, -2.3738, -2.3738],\n          [ 0.8886,  0.7999,  0.7113,  ..., -2.4092, -2.4092, -2.4092],\n          ...,\n          [-0.9731, -1.1681, -1.2745,  ..., -1.9837, -1.9837, -1.9837],\n          [-1.2922, -1.4163, -0.8312,  ..., -1.9837, -1.9837, -1.9660],\n          [-1.1149, -0.7958, -1.0263,  ..., -1.9837, -1.9660, -1.9482]],\n\n         [[ 0.6908,  0.4632,  0.3494,  ..., -2.0024, -2.0024, -2.0214],\n          [ 0.6908,  0.4822,  0.3684,  ..., -1.9645, -1.9645, -1.9645],\n          [ 0.7098,  0.5391,  0.3684,  ..., -1.9645, -1.9645, -1.9645],\n          ...,\n          [-1.0920, -1.3196, -1.4334,  ..., -1.6800, -1.6800, -1.6800],\n          [-1.5472, -1.6800, -1.0541,  ..., -1.6800, -1.6800, -1.6610],\n          [-1.4144, -1.0730, -1.3196,  ..., -1.6800, -1.6610, -1.6420]],\n\n         [[-0.4598, -0.7644, -0.9472,  ..., -1.7190, -1.7190, -1.7394],\n          [-0.4801, -0.7441, -0.9472,  ..., -1.7190, -1.7190, -1.7190],\n          [-0.4801, -0.7035, -0.9472,  ..., -1.7190, -1.7190, -1.7190],\n          ...,\n          [-1.2113, -1.4550, -1.5972,  ..., -1.4956, -1.4956, -1.4956],\n          [-1.6175, -1.8003, -1.1300,  ..., -1.4956, -1.4956, -1.4753],\n          [-1.4550, -1.0894, -1.3941,  ..., -1.4956, -1.4753, -1.4550]]],\n\n\n        [[[ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n          [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n          [ 1.5978,  1.5978,  1.5978,  ...,  1.1723,  1.1900,  1.1900],\n          ...,\n          [ 1.1723,  1.1545,  1.1368,  ...,  0.6936,  0.7467,  0.7999],\n          [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822],\n          [ 1.1723,  1.1545,  1.1368,  ...,  0.6758,  0.7467,  0.7822]],\n\n         [[ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n          [ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n          [ 1.5253,  1.5253,  1.5253,  ...,  1.1081,  1.1460,  1.1460],\n          ...,\n          [ 0.2546,  0.2356,  0.2167,  ..., -0.2765, -0.2196, -0.1627],\n          [ 0.2546,  0.2356,  0.2167,  ..., -0.2954, -0.2196, -0.1816],\n          [ 0.2546,  0.2356,  0.2167,  ..., -0.2954, -0.2196, -0.1816]],\n\n         [[ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n          [ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n          [ 0.9417,  0.9417,  0.9417,  ...,  0.6979,  0.7182,  0.7182],\n          ...,\n          [-0.2364, -0.2567, -0.2770,  ..., -0.5410, -0.4598, -0.3785],\n          [-0.2364, -0.2567, -0.2770,  ..., -0.5410, -0.4395, -0.3988],\n          [-0.2364, -0.2567, -0.2770,  ..., -0.5207, -0.4395, -0.3785]]]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:41.426380300Z",
     "start_time": "2023-12-10T16:00:41.399299600Z"
    }
   },
   "id": "2fa8d698ceee338b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3D images\n",
    "* important in e.g. medical imaging applications (e.g. CT scans):\n",
    "    * Sequences of images stacked along the head to foot axis (representing different topological levels)\n",
    "    * In CT scans, the intensity represents the particle density in different parts of the body\n",
    "    * CT scans only have 1 color channel (like grayscale images)\n",
    "    * 3-dimensional images: 3rd dimension: stacking 2d images on top of each other"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afd9e80f702ce21d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:07:38.712983100Z",
     "start_time": "2023-12-10T16:07:38.704433200Z"
    }
   },
   "id": "e27c4a8b510d91ef"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n       ...,\n       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_path = 'tabular_wine.csv'\n",
    "wine_np = np.loadtxt(wine_path, dtype=np.float32, delimiter=';', skiprows=1) # specify the file path, the dtype, the delimiter used to separate values & the fact that the first row should be skipped\n",
    "wine_np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:09:20.092896300Z",
     "start_time": "2023-12-10T16:09:20.068007600Z"
    }
   },
   "id": "dff19f5b672d95ca"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4898, 12]), torch.float32)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wine_np)\n",
    "wineq.shape, wineq.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T16:13:56.981468700Z",
     "start_time": "2023-12-10T16:13:56.978428700Z"
    }
   },
   "id": "9d5e5fd6fc1484fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9514cf0758e9769e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
